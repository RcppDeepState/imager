<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Foreground/background segmentation using imager</title>

<script src="foreground_background_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="foreground_background_files/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="foreground_background_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="foreground_background_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="foreground_background_files/bootstrap-3.3.5/shim/respond.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="foreground_background_files/highlight/default.css"
      type="text/css" />
<script src="foreground_background_files/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="foreground_background_files/navigation-1.0/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Foreground/background segmentation using imager</h1>

</div>

<div id="TOC">
<ul>
<li><a href="#k-nearest-neighbour-approach"><span class="toc-section-number">1</span> K-nearest neighbour approach</a></li>
<li><a href="#gradient-based-algorithm"><span class="toc-section-number">2</span> Gradient-based algorithm</a></li>
</ul>
</div>

<p><a href="http://sites.google.com/site/simonbarthelme">Simon Barthelmé</a> (GIPSA-lab, CNRS)</p>
<p>Foreground-background separation is a segmentation task, where the goal is to split the image into foreground and background. In semi-interactive settings, the user marks some pixels as “foreground”, a few others as “background”, and it’s up to the algorithm to classify the rest of the pixels.</p>
<div id="k-nearest-neighbour-approach" class="section level1">
<h1><span class="header-section-number">1</span> K-nearest neighbour approach</h1>
<p>The first approach is similar to the <a href="http://www.siox.org/">SIOX</a> algorithm implemented in the Gimp. It assumes that foreground and background have different colours, and models the segmentation task as a (supervised) classification problem, where the user has provided examples of foreground pixels, examples of background pixels, and we need to classify the rest of the pixels according to colour. Since we do not have a parametric model in mind, a simple and robust approach is to use k-nearest neighbour classification.</p>
<p>There are many implementations of the kNN algorithm available for R but the fastest one I’ve found is in the <em>nabor</em> package. The following function implements (binary) knn classification:</p>
<pre class="r"><code>##X is training data 
##Xp is test data
##cl: labels for the rows of X
##k = number of neighbours
##Returns average value of k nearest neighbours
fknn &lt;- function(X,Xp,cl,k=1)
{
    out &lt;- nabor::knn(X,Xp,k=k)
    cl[as.vector(out$nn.idx)] %&gt;% matrix(dim(out$nn.idx)) %&gt;% rowMeans
}</code></pre>
<p>The picture we’ll use comes from Wikipedia:</p>
<pre class="r"><code>im &lt;- load.image(&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Aster_Tataricus.JPG/1024px-Aster_Tataricus.JPG&quot;)
plot(im)</code></pre>
<p><img src="foreground_background_files/figure-html/unnamed-chunk-2-1.png" width="624" /></p>
<p>I hand-selected background and foreground regions (you can do so as well using grabRect):</p>
<pre class="r"><code>#Coordinates of a foreground rectangle (x0,y0,x1,y1)
fg &lt;- c(510,521,670,671 )
#Background
bg &lt;- c(791,   28, 1020,  194 )
#Corresponding pixel sets
px.fg &lt;- ((Xc(im) %inr% fg[c(1,3)]) &amp; (Yc(im) %inr% fg[c(2,4)]))
px.bg &lt;- ((Xc(im) %inr% bg[c(1,3)]) &amp; (Yc(im) %inr% bg[c(2,4)]))

plot(im)
highlight(px.fg)
highlight(px.bg,col=&quot;blue&quot;)</code></pre>
<p><img src="foreground_background_files/figure-html/unnamed-chunk-3-1.png" width="624" /></p>
<p>Next we form our training and test data. These need to be triplets of colour values, and for such purposes the CIELAB colour space works well.</p>
<pre class="r"><code>im.lab &lt;- sRGBtoLab(im)
#Reshape image data into matrix with 3 columns 
cvt.mat &lt;- function(px) matrix(im.lab[px],sum(px)/3,3)
fgMat &lt;- cvt.mat(px.fg)
bgMat &lt;- cvt.mat(px.bg)
labels &lt;- c(rep(1,nrow(fgMat)),rep(0,nrow(bgMat)))</code></pre>
<p>For the test data we’ll use all the pixels in the image. It’s redundant (some of those pixels are already categorised) but saves us some reshaping later on:</p>
<pre class="r"><code>testMat &lt;- cvt.mat(px.all(im))</code></pre>
<p>We’re now ready to run the knn algorithm:</p>
<pre class="r"><code>out &lt;- fknn(rbind(fgMat,bgMat),testMat,cl=labels,k=5)</code></pre>
<p>out gives the proportion of foreground pixels among the k-nearest neighbours: it works as a confidence measure. We reshape the output into a mask:</p>
<pre class="r"><code>msk &lt;- as.cimg(rep(out,3),dim=dim(im))
plot(msk)</code></pre>
<p><img src="foreground_background_files/figure-html/unnamed-chunk-7-1.png" width="624" /></p>
<p>Here’s the final result:</p>
<pre class="r"><code>plot(im*msk)</code></pre>
<p><img src="foreground_background_files/figure-html/unnamed-chunk-8-1.png" width="624" /></p>
</div>
<div id="gradient-based-algorithm" class="section level1">
<h1><span class="header-section-number">2</span> Gradient-based algorithm</h1>
<p>The idea for this algorithm is borrowed from a <a href="http://opensource.graphics/how-to-code-a-nice-user-guided-foreground-extraction-algorithm/">blog post</a> by David Tschumperlé. The goal is to select by hand a few points in the foreground of an image, a few points in the background, and let software do the rest.</p>
<p>The initial locations (blue and red dots) are called seed points. The way the algorithm works is by spreading region labels outwards from the seed points, but stopping at object boundaries. The first step is to do some edge detection, in order to infer object boundaries. Edges are regions in the image where the luminance changes a lot, so a traditional recipe for edge detection is to use the image gradient:</p>
<pre class="r"><code>grad &lt;- imgradient(parrots,&quot;xy&quot;)
str(grad)</code></pre>
<pre><code>## List of 2
##  $ x: cimg [1:768, 1:512, 1, 1:3] 0.00139 0.00612 0.0022 -0.00172 0.00254 ...
##  $ y: cimg [1:768, 1:512, 1, 1:3] 0.01119 0.00923 0.00646 0.00335 0.00287 ...
##  - attr(*, &quot;class&quot;)= chr [1:2] &quot;imlist&quot; &quot;list&quot;</code></pre>
<pre class="r"><code>layout(t(1:2))
plot(grad$x,main=&quot;Gradient along x&quot;)
plot(grad$y,main=&quot;Gradient along y&quot;)</code></pre>
<p><img src="foreground_background_files/figure-html/gradient-1.png" width="1152" /></p>
<p>What we now have is a list of two images, one corresponding to the gradient in the x direction and the gradient in the y dimension. Both are computed across the RGB channels separately.</p>
<p>The image gradient isn’t quite what we need yet, since a light-to-dark edge will have negative gradient while a dark-to-light edge will have positive gradient. A good solution is to square the gradient:</p>
<pre class="r"><code>grad.sq &lt;- grad %&gt;% llply(function(v) v^2)
layout(t(1:2))
plot(sqrt(grad.sq$x),main=&quot;Gradient magnitude along x&quot;)
plot(sqrt(grad.sq$y),main=&quot;Gradient magnitude along y&quot;)</code></pre>
<p><img src="foreground_background_files/figure-html/squaring_gradient-1.png" width="1152" /></p>
<p>Since we don’t care about the direction of the gradient we can just sum the two:</p>
<pre class="r"><code>grad.sq &lt;- add(grad.sq) #Add (d/dx)^2 and (d/dy)^2
plot(sqrt(grad.sq))</code></pre>
<p><img src="foreground_background_files/figure-html/avg_grad-1.png" width="624" /></p>
<p>and finally we combine all three colour channels by summing:</p>
<pre class="r"><code>edges &lt;- imsplit(grad.sq,&quot;c&quot;) %&gt;% add
plot(sqrt(edges),main=&quot;Detected edges&quot;)</code></pre>
<p><img src="foreground_background_files/figure-html/edges-1.png" width="624" /></p>
<p>We have too many edges: for example, the edges around the eyes are spurious (they’re not true object boundaries). A way of mitigating the problem is to operate at a lower resolution. I’ll wrap everything into a function</p>
<pre class="r"><code>#Sigma is the size of the blur window.

detect.edges &lt;- function(im,sigma=1)
    {
        isoblur(im,sigma) %&gt;% imgradient(&quot;xy&quot;) %&gt;% llply(function(v) v^2) %&gt;% add %&gt;% imsplit(&quot;c&quot;) %&gt;% add
    }

detect.edges(parrots,5) %&gt;% sqrt %&gt;% plot</code></pre>
<p><img src="foreground_background_files/figure-html/detect_edges-1.png" width="624" /></p>
<p>The next step is to use the watershed algorithm for label propagation. The watershed algorithm propagates labels (non-zero pixels) to their non-labelled (zero-valued) neighbours according to a priority map. Labels get propagated first to neighbours with high priority. Here we’re going to give higher priority to non-edge neighbouts. David Tschumperlé uses the following heuristic:</p>
<pre class="r"><code>pmap &lt;- 1/(1+edges) #Priority inv. proportional to gradient magnitude
plot(pmap,main=&quot;Priority map&quot;) #Nice metal plate effect! </code></pre>
<p><img src="foreground_background_files/figure-html/pmap-1.png" width="624" /></p>
<p>The other element needed for the watershed transform is an image of the same size as pmap, with a few labelled (non-zero) pixels. We’ll start with two:</p>
<pre class="r"><code>seeds &lt;- imfill(width(pmap),height(pmap)) #Empty image
seeds[400,50,1,1] &lt;- 1 #Background pixel 
seeds[600,450,1,1] &lt;- 2 #Foreground pixel</code></pre>
<p>and we can now run the watershed transform:</p>
<pre class="r"><code>wt &lt;- watershed(seeds,pmap)
plot(wt,main=&quot;Watershed segmentation&quot;)</code></pre>
<p><img src="foreground_background_files/figure-html/watershed-1.png" width="624" /></p>
<p>We can use the result as a mask:</p>
<pre class="r"><code>mask &lt;- add.colour(wt) #We copy along the three colour channels
layout(t(1:2))
plot(parrots*(mask==1),main=&quot;Background&quot;)</code></pre>
<pre><code>## Warning in plot(parrots * (mask == 1), main = &quot;Background&quot;): Méthodes
## incompatibles (&quot;Ops.cimg&quot;, &quot;Ops.pixset&quot;) pour &quot;*&quot;</code></pre>
<pre class="r"><code>plot(parrots*(mask==2),main=&quot;Foreground&quot;)</code></pre>
<pre><code>## Warning in plot(parrots * (mask == 2), main = &quot;Foreground&quot;): Méthodes
## incompatibles (&quot;Ops.cimg&quot;, &quot;Ops.pixset&quot;) pour &quot;*&quot;</code></pre>
<p><img src="foreground_background_files/figure-html/mask-1.png" width="1152" /></p>
<p>Not perfect but pretty good already!</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
